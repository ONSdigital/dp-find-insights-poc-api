# aws-database

XXX THIS RELATES TO THE "OLD DB" (WITH MANY TABLES/COLS RATHER THAN THE "NEW DB")

Various scripts to provision & load data into a AWS RDS (Postgres 13.4)
instance used by the Find Insights back-end team.

Most are dependent on the existance of Postgres client utilities being
installed and also a configured aws command line client.

* create.env.asc
  * Encrypted version of postgres password - currently same for "postgres" (admin
user) & "insights" (app user)

Decrypt
```
gpg -d create.env.asc
```

to create "create.env"

* import.sh
  * This is currently the most manual and problematic process (currently owned by Steve)
  * It takes as input CSV files generated by "Glue" processes (currently owned by Viv/DV)
    * https://github.com/ONSdigital/fi-census-data/tree/main/2011/atlas/viv
    * These in turn have been created from https://github.com/ONSdigital/fi-census-data/tree/main/2011/atlas/lsoa-src
  * 'import.sh' calls a forked version of pgfutter to create and populate the
    tables from CSV.
    * https://github.com/stmuk/pgfutter/tree/develop
 
  * And produces a Postgres SQL dump suitable for use by 'awsloaddata.sh'

* awscreate.sh
  * Tactical solution to create AWS RDS instance and security group opening (non-standard) postgres port of 54322.
  * Probably should be migrated to Terraform.

* awsloaddata.sh
  * creates "insights" pg user & imports "insights.sql" DB dump when ran with '-create-user' flag
  * ommitting the flag just imports insights.sql"
    * 'dropdb insights && createdb' insights should be ran first in the latter case

